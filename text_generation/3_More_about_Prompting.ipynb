{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTiSyI5mJ0Lo"
   },
   "source": [
    "# 3. More about Prompting\n",
    "\n",
    "Welcom to the Third Lesson of the NNLG Tutorial!\n",
    "\n",
    "In this session, we will learn about:\n",
    "\n",
    "- Integrating previous queries\n",
    "\n",
    "- Chain-of-Thought\n",
    "\n",
    "- Few-Shot\n",
    "\n",
    "Let's start by loading the model ([`HuggingFaceTB/SmolLM2-1.7B-Instruct`](https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct)) and  the trivia dataset ([`mandarjoshi/trivia_qa`](https://huggingface.co/datasets/mandarjoshi/trivia_qa)) from the previous lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205,
     "referenced_widgets": [
      "9967515cfdae467cb1d744c94134f9c6",
      "32979aaf426e4e81a02794b474308059",
      "16a365c5e4554f3bbe4cbf8244bcc0a0",
      "03d7bb1d322f42788f9a4fabc9d7cb3b",
      "89a7cc5705c14687ac147537b8e98e88",
      "27001bccad424ace9fb80c3aa7c15f2d",
      "c9c9fc6a64c84f5a8a0617b7448fb318",
      "bc6bac6f20204ac091026d7e96957857",
      "41106650259241998859dc9510f6c0d6",
      "ee450270a4444d81883b853a908cec28",
      "76e9be0819f540a4a43d75466fb7c5b5",
      "b24fe366d7044062a65ecc3592f29478",
      "45991a6b2afa4af48f1f8f95812ea285",
      "b5f7219a8a1844a68f02a7be4dee4ee0",
      "b667e7896fef4f708ba73a4e9078b114",
      "c2488ea6fd644530a50b95119f9f83b8",
      "09acd468053a47079a3078886af751f3",
      "5b1a659955ee4a968d942f3ccc31b89b",
      "19cb4477e62b46e1b29d17eabeeb8bef",
      "afb84676c9c940a7bbf13bbfaa6af273",
      "545de02d27f64681a4e0898deef3c3ca",
      "7cc586bc91fe4a09811f8ccc89a39485"
     ]
    },
    "id": "_5zM81kjol5-",
    "outputId": "4c1c220d-aa48-4d6c-ed3f-433b52ae9295"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Install Transformers Library\n",
    "! pip install transformers --quiet\n",
    "\n",
    "# Import Pipeline for the LLM and Pytorch to find the best available device\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Find the best available device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') # Use GPU if available, otherwise use CPU\n",
    "\n",
    "# Load the model\n",
    "model_identifier = 'HuggingFaceTB/SmolLM2-1.7B-Instruct'\n",
    "llm = pipeline(model=model_identifier, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iAv5odz_VlpS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614c07e054e74168be14f1efbdf37492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2156772b5a24749b4cba541f3325b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Which American-born Sinclair won the Nobel Prize for Literature in 1930?',\n",
       " 'answer': 'Sinclair Lewis',\n",
       " 'wiki_context': []}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install Datasets library\n",
    "! pip install datasets --quiet\n",
    "\n",
    "# Import load_dataset and Dataset\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# Instantiate the Trivia QA dataset in streaming model\n",
    "dataset = load_dataset(\n",
    "    'mandarjoshi/trivia_qa',\n",
    "    'rc',\n",
    "    split='train',\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "# Preprocess the dataset\n",
    "def preprocess_trivia_qa(sample):\n",
    "    wiki_context = []\n",
    "    for title, context in zip(sample['entity_pages']['title'], sample['entity_pages']['wiki_context']):\n",
    "        wiki_context.append(tuple([title, context]))\n",
    "    new_sample = {\n",
    "        'wiki_context':wiki_context,\n",
    "        'answer':sample['answer']['value']\n",
    "    }\n",
    "    return new_sample\n",
    "\n",
    "dataset = dataset.map(\n",
    "    preprocess_trivia_qa,\n",
    "    remove_columns=[\n",
    "        'question_id',\n",
    "        'question_source',\n",
    "        'entity_pages',\n",
    "        'search_results'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Take the first 8 elements ofthe dataset\n",
    "dataset = dataset.take(8)\n",
    "\n",
    "# Convert from IterableDataset to Dataset\n",
    "dataset = Dataset.from_generator(lambda: iter(dataset), features=dataset.features)\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17qqPCtfVqdV"
   },
   "source": [
    "\n",
    "Las time we observed that, although many of the generated answers were correct, they were vey verbose. A first approach to solve this could be asking the model to answer in as few words as possible:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JuCf6E8dVmyo",
    "outputId": "4f58f5c7-2e34-48d0-b51f-d75b2ce660de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:   Which American-born Sinclair won the Nobel Prize for Literature in 1930?\n",
      "Answer:     Sinclair Lewis\n",
      "Generation: F. Scott Fitzgerald\n",
      "\n",
      "Question:   Where in England was Dame Judi Dench born?\n",
      "Answer:     York\n",
      "Generation: England.\n",
      "\n",
      "Question:   In which decade did Billboard magazine first publish and American hit chart?\n",
      "Answer:     30s\n",
      "Generation: 1950s\n",
      "\n",
      "Question:   From which country did Angola achieve independence in 1975?\n",
      "Answer:     Portugal\n",
      "Generation: Angola\n",
      "\n",
      "Question:   Which city does David Soul come from?\n",
      "Answer:     Chicago\n",
      "Generation: New York\n",
      "\n",
      "Question:   Who won Super Bowl XX?\n",
      "Answer:     Chicago Bears\n",
      "Generation: Patriots\n",
      "\n",
      "Question:   Which was the first European country to abolish capital punishment?\n",
      "Answer:     Norway\n",
      "Generation: Sweden.\n",
      "\n",
      "Question:   In which country did he widespread use of ISDN begin in 1988?\n",
      "Answer:     Japan\n",
      "Generation: Germany\n",
      "\n",
      "CPU times: user 1min 31s, sys: 1.52 s, total: 1min 32s\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for sample in dataset:\n",
    "\n",
    "    conversation = [\n",
    "        {\n",
    "            'role':'system',\n",
    "            'content':'''You are a helpful assistant.'''\n",
    "        },\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':'Answer the following question using as few words as possible: '+sample['question']\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    prompt = llm.tokenizer.apply_chat_template(conversation, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    generation = llm(prompt, max_new_tokens = 32)\n",
    "\n",
    "    new_text = generation[0]['generated_text'][len(prompt):]\n",
    "\n",
    "    print('Question:  ', sample['question'])\n",
    "    print('Answer:    ', sample['answer'])\n",
    "    print('Generation:', new_text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mo2FdJHaaIL_"
   },
   "source": [
    "## 3.1 Integration of previous Queries and Chain of Thought\n",
    "\n",
    "While now the answers are short and concise, more in line with what we expected, they are less correct than before. By limiting the size of the answer we reduced the accuracy of the model.\n",
    "\n",
    "Let's try something else. Let's generate the long (but more accurate) answers like we did on the previous lesson and **then** have the model rephrase it so that it is short and concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 998
    },
    "id": "CChTjivDW8G3",
    "outputId": "4589e311-1a3d-4319-9429-54a91bbffc21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:     Which American-born Sinclair won the Nobel Prize for Literature in 1930?\n",
      "Answer:       Sinclair Lewis\n",
      "long answer:  The American-born Sinclair who won the Nobel Prize for Literature in 1930 was Sinclair Lewis. He was the first American author to win the Nobel\n",
      "short answer: Sinclair\n",
      "\n",
      "Question:     Where in England was Dame Judi Dench born?\n",
      "Answer:       York\n",
      "long answer:  Dame Judi Dench was born in London, England.\n",
      "short answer: London, England.\n",
      "\n",
      "Question:     In which decade did Billboard magazine first publish and American hit chart?\n",
      "Answer:       30s\n",
      "long answer:  Billboard magazine first published and American hit chart in the 1950s.\n",
      "short answer: 1950s\n",
      "\n",
      "Question:     From which country did Angola achieve independence in 1975?\n",
      "Answer:       Portugal\n",
      "long answer:  Angola achieved independence from Portugal in 1975.\n",
      "short answer: Portugal.\n",
      "\n",
      "Question:     Which city does David Soul come from?\n",
      "Answer:       Chicago\n",
      "long answer:  David Soul is an American actor best known for his role as Detective Elliot Stabler in the television series \"Law & Order: Special Victims Unit.\"\n",
      "short answer: New York\n",
      "\n",
      "Question:     Who won Super Bowl XX?\n",
      "Answer:       Chicago Bears\n",
      "long answer:  The New England Patriots won Super Bowl XX.\n",
      "short answer: Patriots\n",
      "\n",
      "Question:     Which was the first European country to abolish capital punishment?\n",
      "Answer:       Norway\n",
      "long answer:  The first European country to abolish capital punishment was the Netherlands. On 17 March 1870, the Netherlands abolished the death penalty for all crimes\n",
      "short answer: Netherlands\n",
      "\n",
      "Question:     In which country did he widespread use of ISDN begin in 1988?\n",
      "Answer:       Japan\n",
      "long answer:  The widespread use of ISDN (Integrated Services Digital Network) began in 1988 in the United Kingdom.\n",
      "short answer: UK\n",
      "\n",
      "CPU times: user 11min 3s, sys: 12.5 s, total: 11min 16s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for sample in dataset:\n",
    "\n",
    "    # Generate the long answer\n",
    "\n",
    "    conversation = [\n",
    "        {\n",
    "            'role':'system',\n",
    "            'content':'''You are a helpful assistant.'''\n",
    "        },\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':'Answer the following question: '+sample['question']\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    prompt = llm.tokenizer.apply_chat_template(conversation, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    generation = llm(prompt, max_new_tokens = 32)\n",
    "\n",
    "    # Shorten the answer\n",
    "\n",
    "    long_answer = generation[0]['generated_text'][len(prompt):]\n",
    "\n",
    "    conversation += [\n",
    "        {\n",
    "            'role':'assistant',\n",
    "            'content': long_answer\n",
    "        },\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':'Consider the previous question and your answer, then answer the question again in as few words as possible.'\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    prompt = llm.tokenizer.apply_chat_template(conversation, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    generation = llm(prompt, max_new_tokens = 32)\n",
    "\n",
    "    short_answer = generation[0]['generated_text'][len(prompt):]\n",
    "\n",
    "    print('Question:    ', sample['question'])\n",
    "    print('Answer:      ', sample['answer'])\n",
    "    print('long answer: ', long_answer)\n",
    "    print('short answer:', short_answer)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqRcCLGPmDDM"
   },
   "source": [
    "## 3.2 Chain-of-Thought and Few-shot\n",
    "\n",
    "That looks much better! However, now we are doing twice the computation. Maybe we can get away with doing both things in a single go. But we will need Few-shot to ensure that the model follows the expected format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yWtTfHO5cgm6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:   Which American-born Sinclair won the Nobel Prize for Literature in 1930?\n",
      "Answer:     Sinclair Lewis\n",
      "The American-born Sinclair who won the Nobel Prize for Literature in 1930 was Sinclair Lewis.\n",
      "Shortest form: Sinclair Lewis.\n",
      "\n",
      "Question:   Where in England was Dame Judi Dench born?\n",
      "Answer:     York\n",
      "Dame Judi Dench was born in London, England.\n",
      "Shortest form: London, England.\n",
      "\n",
      "Question:   In which decade did Billboard magazine first publish and American hit chart?\n",
      "Answer:     30s\n",
      "Billboard magazine first published and American hit chart in the 1950s.\n",
      "Shortest form: 1950s.\n",
      "\n",
      "Question:   From which country did Angola achieve independence in 1975?\n",
      "Answer:     Portugal\n",
      "Angola achieved independence from Portugal in 1975.\n",
      "Shortest form: Portugal.\n",
      "\n",
      "Question:   Which city does David Soul come from?\n",
      "Answer:     Chicago\n",
      "David Soul comes from the city of New York.\n",
      "Shortest form: New York.\n",
      "\n",
      "Question:   Who won Super Bowl XX?\n",
      "Answer:     Chicago Bears\n",
      "The team that won Super Bowl XX was the Dallas Cowboys.\n",
      "Shortest form: Dallas Cowboys.\n",
      "\n",
      "Question:   Which was the first European country to abolish capital punishment?\n",
      "Answer:     Norway\n",
      "The first European country to abolish capital punishment was the Netherlands.\n",
      "Shortest form: Netherlands.\n",
      "\n",
      "Question:   In which country did he widespread use of ISDN begin in 1988?\n",
      "Answer:     Japan\n",
      "The widespread use of ISDN began in Germany in 1988.\n",
      "Shortest form: Germany.\n",
      "\n",
      "CPU times: user 9min 46s, sys: 12.9 s, total: 9min 59s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for sample in dataset:\n",
    "\n",
    "    conversation = [\n",
    "        {\n",
    "            'role':'system',\n",
    "            'content':'You are a helpful assistant.'\n",
    "        },\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':'Answer the following question: From which state was the Apollo 11 mission launched?\\nThen answer it again in its shortest form.'\n",
    "        },\n",
    "        {\n",
    "            'role':'assistant',\n",
    "            'content':'The Apollo 11 mission was launched from the state of Florida.\\nShortest from: Florida.'\n",
    "        },\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':'Answer the following question: Who was the author of the novel Frankenstein?\\nThen answer it again in its shortest form.'\n",
    "        },\n",
    "        {\n",
    "            'role':'assistant',\n",
    "            'content':'The author of the novel Frankenstein was Mary Shelly.\\nShortest form: Mary Shelley.'\n",
    "        },\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':'Answer the following question: '+sample['question']+'\\nThen answer it again in its shortest form.'\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    prompt = llm.tokenizer.apply_chat_template(conversation, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    generation = llm(prompt, max_new_tokens = 32)\n",
    "\n",
    "    new_text = generation[0]['generated_text'][len(prompt):]\n",
    "\n",
    "    print('Question:  ', sample['question'])\n",
    "    print('Answer:    ', sample['answer'])\n",
    "    print(new_text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqiiwIPJ_9Yf"
   },
   "source": [
    "We have tested different ways of enforcing the desired output format for this task. On the next lesson we will see how to provide aditional information to the model to overcome it's limitations.\n",
    "\n",
    "## 3.3 Exercise\n",
    "\n",
    "Can you imporve the performance of the LLM on your dataset from the second lesson by using any of the techniques discussed here? Give it a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group A\n",
    "\n",
    "- Oyetunji ABIOYE\n",
    "- Mehsen AZIZI\n",
    "- Mohammad AL TAKACH\n",
    "- Hawawou  Oumarou Tchapchet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "O9L4tUFNmc8u"
   },
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Find the best available device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') # Use GPU if available, otherwise use CPU\n",
    "\n",
    "# Load the model\n",
    "model_identifier = 'unsloth/Llama-3.2-3B-Instruct'\n",
    "llm = pipeline(model=model_identifier, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affcaa18ad1f480f8fcad03583a5d772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    'ImruQays/Rasaif-Classical-Arabic-English-Parallel-texts',\n",
    "    split='train',\n",
    "    streaming=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "├─sample:\n",
      "│ ├─ar: وبعد، فلما كان السلطان الأعظم الملك الناصر، العالم المجاهد المرابط المتاغر، المؤيد المظفر المنصور، زين الدنيا والدين، سلطان الإسلام والمسلمين، محيى العدل فى العالمين، وارث ملك ملوك العرب والعجم والترك، ظل الله فى أرضه، القائم بسنته وفرضه\n",
      "│ ├─en: To proceed: Since the great Sultan, the King, the Victor, the Sage, the Just, the Struggler, the Perseverer, the Trail-blazer, the God-supported, the Conquering, the Victorious, the Ornament of the World and of Religion, the Sultan of Islam and of the Muslims, the Rejuvenator of Justice in the Worlds, the Heir of the kingdom of the Kings of the Arabs and the Persians and the Turks, Shadow of God in His land, the Upholder of God’s sunnah and of His Ordinances.\n"
     ]
    }
   ],
   "source": [
    "sample = dataset.__iter__().__next__()\n",
    "\n",
    "def nested_print(key, element, level=0):\n",
    "    if isinstance(element, dict):\n",
    "        print(f'{\"│ \"*(level)}├─{key}:')\n",
    "        for k, v in element.items():\n",
    "            nested_print(k, v, level+1)\n",
    "    else:\n",
    "        print(f'{\"│ \"*(level)}├─{key}: {element}')\n",
    "\n",
    "nested_print('sample', sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_en_ar(sample):\n",
    "    return {\n",
    "        'source':sample['en'],\n",
    "        'target':sample['ar'],\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(\n",
    "    preprocess_en_ar,\n",
    "    remove_columns=[\n",
    "            'en',\n",
    "            'ar'\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out samples that are too short or too long, we increase the lower bound to 30 because Arabic is a more verbose language\n",
    "def filter_en_ar(sample):\n",
    "    return (len(sample['source']) >= 30) and (len(sample['source']) <= 60) and (len(sample['target']) >= 30) and (len(sample['target']) <= 60)\n",
    "\n",
    "dataset = dataset.filter(filter_en_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.take(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chapter One: about the maintenance of caution generally.',\n",
       " 'Chapter One: about the choosing of the site for camping.',\n",
       " 'Chapter Two: about the method of night raiding.',\n",
       " 'Chapter Three: about the method of investment.',\n",
       " '“You never do anything right!” sighed Abu‘Abdullah.',\n",
       " '“So what should I do?” moaned the sheikh.',\n",
       " 'Thumama got extremely upset when his house burned down.',\n",
       " 'As a result, good drinking water went to waste.',\n",
       " 'Now there’s just the problem of what to do with the blood.',\n",
       " 'Suddenly I saw her relax and smile to herself.',\n",
       " '‘You must have realised what to do with the blood.',\n",
       " 'In general, soups spare you demands for water and wine.',\n",
       " 'Soup fills you up and dulls the appetite.',\n",
       " 'Sip hot soup and you save on fuel bills and padded clothes.',\n",
       " 'Take it from one who knows, as a piece of friendly advice.”',\n",
       " 'I’d become a highway robber, a secret agent or a spy.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_generator(lambda: iter(dataset), features=dataset.features)\n",
    "dataset['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:   Chapter One: about the maintenance of caution generally.\n",
      "Target:     الفصل الأول: فى أخذ الحذر فى الجملة.\n",
      "Generation: The following English text: Chapter One: about the maintenance of caution generally. is translated to Arabic as: فصل أول: عن الحفاظ على الحذر بشكل عام.\n",
      "\n",
      "Source:   Chapter One: about the choosing of the site for camping.\n",
      "Target:     الفصل الأول: فى اختيار موضع المنزل.\n",
      "Generation: The following English text: Chapter One: about the choosing of the site for camping. is translated to Arabic as:kapitول أحد: عن اختيار المكان للاصطلاح.\n",
      "\n",
      "Source:   Chapter Two: about the method of night raiding.\n",
      "Target:     الفصل الثانى: فى كيفية البيات.\n",
      "Generation: The following English text: Chapter Two: about the method of night raiding. is translated to Arabic as: chapter الثانية: عن طريقة الغنaim\n",
      "\n",
      "Source:   Chapter Three: about the method of investment.\n",
      "Target:     الفصل الثالث: فى كيفية الحصار.\n",
      "Generation: The following English text: Chapter Three: about the method of investment. is translated to Arabic as: فصل ثلاثة: عن طريقة الاستثمار.\n",
      "\n",
      "Source:   “You never do anything right!” sighed Abu‘Abdullah.\n",
      "Target:     فقال له الشيخ: لا يجيء والله منك، من صالح أبدا.\n",
      "Generation: The following English text: “You never do anything right!” sighed Abu‘Abdullah. is translated to Arabic as: “لا تفعل أي شيء صحيحًا!” قال أبو Abdullah.\n",
      "\n",
      "Source:   “So what should I do?” moaned the sheikh.\n",
      "Target:     قال الشيخ: فكيف أصنع جعلت فداك؟\n",
      "Generation: The following English text: “So what should I do?” moaned the sheikh. is translated to Arabic as: قال لها الشيخ: ماذا أفعل؟\n",
      "\n",
      "Source:   Thumama got extremely upset when his house burned down.\n",
      "Target:     وقيل: أصبح ثمامة شديد الغمّ حين احترقت داره.\n",
      "Generation: The following English text: Thumama got extremely upset when his house burned down. is translated to Arabic as: ثومام أصبح غاضبًا جداً عندما ساقت أرضه.\n",
      "\n",
      "Source:   As a result, good drinking water went to waste.\n",
      "Target:     فكان ذلك الماء العذب الصافي يذهب باطلا.\n",
      "Generation: The following English text: As a result, good drinking water went to waste. is translated to Arabic as: ونتيجة لذلك، أصبحت الماء الطيب المشراب ضياء.\n",
      "\n",
      "Source:   Now there’s just the problem of what to do with the blood.\n",
      "Target:     ثم قالت: «بقي الآن علينا الانتفاع بالدم.\n",
      "Generation: The following English text: Now there’s just the problem of what to do with the blood. is translated to Arabic as: وفيها الآن-only problem هو ماذا نفعل مع الدم.\n",
      "\n",
      "Source:   Suddenly I saw her relax and smile to herself.\n",
      "Target:     قال: «فلم ألبث أن رأيتها قط طلّقت وتبسّمت.\n",
      "Generation: The following English text: Suddenly I saw her relax and smile to herself. is translated to Arabic as: غاضت لي بسرعة أن أرىها تلاذ وتهز ل herself.\n",
      "\n",
      "Source:   ‘You must have realised what to do with the blood.\n",
      "Target:     فقلت: «ينبغي أن يكون قد انفتح لك باب الرأي في الدم».\n",
      "Generation: The following English text: ‘You must have realised what to do with the blood. is translated to Arabic as: «أنت أدراك ما يجب عليك فعله بالدم».\n",
      "\n",
      "Source:   In general, soups spare you demands for water and wine.\n",
      "Target:     وكل شيء من الإحساء فهو يغني عن طلب النبيذ وشرب الماء.\n",
      "Generation: The following English text: In general, soups spare you demands for water and wine. is translated to Arabic as: في الأصل، تؤخذ السلطات منك الطلبات على الماء والwine.\n",
      "\n",
      "Source:   Soup fills you up and dulls the appetite.\n",
      "Target:     وهي تملأ النفس وتمنع من التشهّي.\n",
      "Generation: The following English text: Soup fills you up and dulls the appetite. is translated to Arabic as: تملأ العصيرك وتقوي الجوع.\n",
      "\n",
      "Source:   Sip hot soup and you save on fuel bills and padded clothes.\n",
      "Target:     وحسو الحار يغني عن الوقود، وعن لبس الحشو.\n",
      "Generation: The following English text: Sip hot soup and you save on fuel bills and padded clothes. is translated to Arabic as: شرب السوupa الدافئة ويساعدك على تخفيض في accounts المياه و الملابس المزودة.\n",
      "\n",
      "Source:   Take it from one who knows, as a piece of friendly advice.”\n",
      "Target:     فخذها من حكيم مجرّب ومن ناصح مشفق.\n",
      "Generation: The following English text: Take it from one who knows, as a piece of friendly advice.” is translated to Arabic as: أتخذها من من يعرف، كأدلة خاليه.\n",
      "\n",
      "Source:   I’d become a highway robber, a secret agent or a spy.\n",
      "Target:     أو خرجت قاطع طريق، أو صرت للقوم عينا ولهم مجهرا.\n",
      "Generation: The following English text: I’d become a highway robber, a secret agent or a spy. is translated to Arabic: سوف أصبح راقب الطرق، مراسلًا سرّيًا أو شبه رجل أسبوع.\n",
      "\n",
      "CPU times: user 1h 21min 5s, sys: 2min 27s, total: 1h 23min 33s\n",
      "Wall time: 10min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for sample in dataset:\n",
    "\n",
    "    conversation = [\n",
    "        {\n",
    "            'role':'system',\n",
    "            'content':'''You are an expert translator specializing in English to Arabic translation.\n",
    "                         If you can't find a translation, you should say: I do not know the answer.'''\n",
    "        },\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':'You must Translate the following English text to Arabic only: Pannum is bread donated charitably to prisoners and beggars.'\n",
    "        },\n",
    "        {\n",
    "            'role':'assistant',\n",
    "            'content':'The following English text: Pannum is bread donated charitably to prisoners and beggars. is translated to Arabic as: البنوم هو خبز يتم التبرع به بشكل خيري للسجناء والمتسولين.'\n",
    "        },\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':'You must Translate the following English text to Arabic only: But then I see them dip it in the mustard.'\n",
    "        },\n",
    "        {\n",
    "            'role':'assistant',\n",
    "            'content':'The following English text: But then I see them dip it in the mustard. is translated to Arabic as:   ولكن بعد ذلك أراهم يغمسونه في الخردل.'\n",
    "        },\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':'You must Translate the following English text to Arabic only: Boy, that chicken was tough. Bring me one that’s tender!'\n",
    "        },\n",
    "        {\n",
    "            'role':'assistant',\n",
    "            'content':'The following English text: Boy, that chicken was tough. Bring me one that’s tender! is translated to Arabic as: يا صبي، كان الدجاج قاسيًا. أحضر لي واحدًا طريًا!'\n",
    "        },\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':'You must Translate the following English text to Arabic only: I praise Him as befits His honor and sublime glory.'\n",
    "        },\n",
    "        {\n",
    "            'role':'assistant',\n",
    "            'content':'The following English text: I praise Him as befits His honor and sublime glory. is translated to Arabic as: أثني عليه كما يليق بعظمته ومجده السامي.'\n",
    "        },\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':'You must Translate the following English text to Arabic only: This vizir was a man of great shrewdness and abilities.'\n",
    "        },\n",
    "        {\n",
    "            'role':'assistant',\n",
    "            'content':'The following English text: This vizir was a man of great shrewdness and abilities. is translated to Arabic as: كان هذا الوزير رجلاً ذا ذكاء وقدرات عظيمة.'\n",
    "        },\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':'You must Translate the following English text to Arabic only: This Yazid was the ancestor of al-Wazir al-Muhallabi.'\n",
    "        },\n",
    "        {\n",
    "            'role':'assistant',\n",
    "            'content':'The following English text: This Yazid was the ancestor of al-Wazir al-Muhallabi. is translated to Arabic as: كان هذا اليزيد سلف الوزير المهلبي.'\n",
    "        },\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':'You must Translate the following English text to Arabic only: He dwell for some time at Abadan and also at Basra.'\n",
    "        },\n",
    "        {\n",
    "            'role':'assistant',\n",
    "            'content':'The following English text: He dwell for some time at Abadan and also at Basra. is translated to Arabic as: عاش لبعض الوقت في آبادان وأيضًا في البصرة.'\n",
    "        },\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':'You must Translate the following English text to Arabic only: This verse forms part of a long qasida.'\n",
    "        },\n",
    "        {\n",
    "            'role':'assistant',\n",
    "            'content':'The following English text: This verse forms part of a long qasida. is translated to Arabic as: يشكل هذا البيت جزءًا من قصيدة طويلة.'\n",
    "        },\n",
    "\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content':'You must Translate the following English text to Arabic only: '+ sample['source']\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    prompt = llm.tokenizer.apply_chat_template(conversation, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    generation = llm(prompt, max_new_tokens = 128)\n",
    "\n",
    "    new_text = generation[0]['generated_text'][len(prompt):]\n",
    "\n",
    "    print('Source:  ', sample['source'])\n",
    "    print('Target:    ', sample['target'])\n",
    "    print('Generation:', new_text)\n",
    "    print()\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nn_speech_recognition-qgr9tgLb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03d7bb1d322f42788f9a4fabc9d7cb3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee450270a4444d81883b853a908cec28",
      "placeholder": "​",
      "style": "IPY_MODEL_76e9be0819f540a4a43d75466fb7c5b5",
      "value": " 792/792 [00:00&lt;00:00, 27.6kB/s]"
     }
    },
    "09acd468053a47079a3078886af751f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16a365c5e4554f3bbe4cbf8244bcc0a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc6bac6f20204ac091026d7e96957857",
      "max": 792,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_41106650259241998859dc9510f6c0d6",
      "value": 792
     }
    },
    "19cb4477e62b46e1b29d17eabeeb8bef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27001bccad424ace9fb80c3aa7c15f2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32979aaf426e4e81a02794b474308059": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27001bccad424ace9fb80c3aa7c15f2d",
      "placeholder": "​",
      "style": "IPY_MODEL_c9c9fc6a64c84f5a8a0617b7448fb318",
      "value": "config.json: 100%"
     }
    },
    "41106650259241998859dc9510f6c0d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "45991a6b2afa4af48f1f8f95812ea285": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09acd468053a47079a3078886af751f3",
      "placeholder": "​",
      "style": "IPY_MODEL_5b1a659955ee4a968d942f3ccc31b89b",
      "value": "model.safetensors:  13%"
     }
    },
    "545de02d27f64681a4e0898deef3c3ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b1a659955ee4a968d942f3ccc31b89b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76e9be0819f540a4a43d75466fb7c5b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7cc586bc91fe4a09811f8ccc89a39485": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89a7cc5705c14687ac147537b8e98e88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9967515cfdae467cb1d744c94134f9c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_32979aaf426e4e81a02794b474308059",
       "IPY_MODEL_16a365c5e4554f3bbe4cbf8244bcc0a0",
       "IPY_MODEL_03d7bb1d322f42788f9a4fabc9d7cb3b"
      ],
      "layout": "IPY_MODEL_89a7cc5705c14687ac147537b8e98e88"
     }
    },
    "afb84676c9c940a7bbf13bbfaa6af273": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b24fe366d7044062a65ecc3592f29478": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_45991a6b2afa4af48f1f8f95812ea285",
       "IPY_MODEL_b5f7219a8a1844a68f02a7be4dee4ee0",
       "IPY_MODEL_b667e7896fef4f708ba73a4e9078b114"
      ],
      "layout": "IPY_MODEL_c2488ea6fd644530a50b95119f9f83b8"
     }
    },
    "b5f7219a8a1844a68f02a7be4dee4ee0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19cb4477e62b46e1b29d17eabeeb8bef",
      "max": 3422777952,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_afb84676c9c940a7bbf13bbfaa6af273",
      "value": 440401920
     }
    },
    "b667e7896fef4f708ba73a4e9078b114": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_545de02d27f64681a4e0898deef3c3ca",
      "placeholder": "​",
      "style": "IPY_MODEL_7cc586bc91fe4a09811f8ccc89a39485",
      "value": " 440M/3.42G [00:10&lt;01:12, 41.0MB/s]"
     }
    },
    "bc6bac6f20204ac091026d7e96957857": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2488ea6fd644530a50b95119f9f83b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9c9fc6a64c84f5a8a0617b7448fb318": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee450270a4444d81883b853a908cec28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
