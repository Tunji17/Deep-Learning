{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixpGchAgNicZ"
   },
   "source": [
    "# 5. Choosing, Loading and Using Metrics for Automatic Evaluation\n",
    "\n",
    "Welcome to the 5th session of the LLM tutorial!\n",
    "\n",
    "Congratulations! Through the previous sessions, you've learned how to use LLMs to generate text in various creative and effective ways (e.g., using prompts, RAG, etc.).\n",
    "\n",
    "In the final two sessions, we will focus on the evaluation of LLMs, exploring how to evaluate models efficiently and effectively.\n",
    "\n",
    "The goal of **this session** is to learn how to use common automatic metrics to assess the performance of LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0ycKyXmQkJM"
   },
   "source": [
    "## 5.1 Introduction to Automatic Evaluation Metric\n",
    "\n",
    "**Automatic metrics** are automated standards for evaluating the performance of NLP models **without requiring human intervention** during the evaluation process.\n",
    "\n",
    "Based on different categorization methods, these metrics can be grouped into the following categories:\n",
    "- **Reference-based** vs. **Reference-free**:\n",
    "    - **Reference-based metrics** (e.g., BLEU, TER) compare the generated text against reference texts to assess similarity.\n",
    "    - **Reference-free metrics** evaluate the generated text directly, without requiring reference texts. These can focus on:\n",
    "        - **Fluency and linguistic quality** (e.g., Perplexity), which measures how well the generated text aligns with the statistical patterns of a language model's training data.\n",
    "        - **Input alignment** (e.g., tasks like entailment detection or faithfulness metrics), which directly evaluate the relationship between the input and output without comparing to reference texts.\n",
    "- **Design structure (Pattern-matched vs. Semantics-based)**:\n",
    "    - **Pattern-matched metrics** assess surface-level overlap between generated and reference texts, such as n-gram matches (e.g. BLEU, ROUGE)\n",
    "    - **Semantics-based metrics** evaluate the semantic similarity of the texts, focusing on meaning rather than exact word matching (e.g., BERTScore).\n",
    "- **Task-specific metrics**:\n",
    "    - These are tailored for specific NLP tasks, such as BLEU for machine translation, ROUGE for text summarization, and Accuracy for classification/retrieval problem.\n",
    "\n",
    "It's important to emphasize that **there is no perfect metric**—each has its limitations. Therefore, it is crucial to select metrics based on the specific requirements and goals of your task.\n",
    "\n",
    "In this session, we will explore how to use different metrics with Huggingface Evaluate Library to evaluate a machine translation model (EN-FR).\n",
    "\n",
    "**Note.** Before you start running the code, please activate one GPU: runtime -> change runtime type -> T4 ([How to activate GPU in Colab?](https://saturncloud.io/blog/how-to-activate-gpu-computing-in-google-colab/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jDhosO0ZrOI"
   },
   "source": [
    "## 5.2 Enviroment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I2z0Q2FSZ2kt",
    "outputId": "28429a04-f162-4887-f415-0d24e883a3ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -q datasets\n",
    "! pip install -q transformers\n",
    "! pip install -q evaluate\n",
    "! pip install -q tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSepl9QrYe7F"
   },
   "source": [
    "## 5.3 Load a EN-FR dataset\n",
    "We will use a dataset with translations from English to French. You can preview the data [here](https://huggingface.co/datasets/Helsinki-NLP/opus_books/viewer/en-fr)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsxQ52eEpGQ1",
    "outputId": "d6e4d9c9-4ea4-45fd-be80-73c417f1405c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'translation'],\n",
      "    num_rows: 100\n",
      "})\n",
      "{'id': '0', 'translation': {'en': 'The Wanderer', 'fr': 'Le grand Meaulnes'}}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load part of the dataset to speed up the evaluation (optional)\n",
    "data = load_dataset(\"Helsinki-NLP/opus_books\", \"en-fr\", split='train[:100]') # 100 items of the dataset\n",
    "\n",
    "# Show data structure\n",
    "print(data)\n",
    "\n",
    "# Print the first instance of data\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data:  (100, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the data: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erEyiyDLbA0Z"
   },
   "source": [
    "## 5.4 Load a LLM for translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1W184aDAaZq0",
    "outputId": "ec944c12-8f46-4306-e7fa-d5b82055a73c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "# Check if GPU is available\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "\n",
    "# Set up model name (Feel free to try different models)\n",
    "model_name = \"google-t5/t5-small\"\n",
    "\n",
    "# Define translator\n",
    "if torch.cuda.is_available():\n",
    "    translator = pipeline(\"translation_en_to_fr\", model=model_name, device=0)\n",
    "else:\n",
    "    translator = pipeline(\"translation_en_to_fr\", model=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Erw_5fFUf7Q-"
   },
   "source": [
    "Here is an example to translate a few sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MgDNGXCRgfP8",
    "outputId": "8776bc4e-e551-4f14-9b47-ee799737d17a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Good morning\n",
      "Translated: Bonjour\n",
      "\n",
      "Original: How are you?\n",
      "Translated: Comment êtes-vous?\n",
      "\n",
      "Original: This is a test for batch translation.\n",
      "Translated: Il s'agit d'un test pour la traduction par lots.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example list\n",
    "texts = [\"Good morning\", \"How are you?\", \"This is a test for batch translation.\"]\n",
    "\n",
    "# Perform batch translation\n",
    "translations = translator(texts)\n",
    "\n",
    "# Print translations\n",
    "for i, translation in enumerate(translations):\n",
    "    print(f\"Original: {texts[i]}\")\n",
    "    print(f\"Translated: {translation['translation_text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "CXpbWbBVhgR4"
   },
   "outputs": [],
   "source": [
    "# Create a French translation for the English data\n",
    "from tqdm import tqdm\n",
    "def translation_en_to_fr(data, translator):\n",
    "    # We first merge all english text into one list\n",
    "    text_en_list = [i['translation']['en'] for i in data]\n",
    "    ref_fr_list = [i['translation']['fr'] for i in data]\n",
    "\n",
    "    # Process in batches with tqdm for progress\n",
    "    batch_size = 16\n",
    "    french_translation = []\n",
    "    for i in tqdm(range(0, len(text_en_list), batch_size)):\n",
    "        batch_texts = text_en_list[i:i+batch_size]\n",
    "        batch_translations = translator(batch_texts)\n",
    "        french_translation.extend(batch_translations)\n",
    "\n",
    "    return text_en_list, ref_fr_list, french_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QrQ2HrkOh6HN",
    "outputId": "4d4e9dbd-210a-449b-af2a-ece5ca4d557b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [02:15<00:00, 19.35s/it]\n"
     ]
    }
   ],
   "source": [
    "text_en, ref_fr, predict_fr = translation_en_to_fr(data, translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original English Text:  The Wanderer\n",
      "Original French Text:  Le grand Meaulnes\n",
      "Predicted French Text:  {'translation_text': 'Le Wanderer'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Original English Text: \", text_en[0])\n",
    "print(\"Original French Text: \", ref_fr[0])\n",
    "\n",
    "print(\"Predicted French Text: \", predict_fr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5oNxwLifl0kf",
    "outputId": "0a38b3cd-bdcd-4f3a-d756-225ca6ba2638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: I still say 'our home,' although the house no longer belongs to us.\n",
      "Reference: Je continue à dire « chez nous », bien que la maison ne nous appartienne plus.\n",
      "Predicted: Je dirais encore « notre maison », même si la maison ne nous appartient plus.\n",
      "\n",
      "English: We left that part of the country nearly fifteen years ago and shall certainly never go back to it.\n",
      "Reference: Nous avons quitté le pays depuis bientôt quinze ans et nous n’y reviendrons certainement jamais.\n",
      "Predicted: Nous avons quitté cette partie du pays il y a près de quinze ans et ne reviendrons certainement jamais à celle-ci.\n",
      "\n",
      "English: We were living in the building of the Higher Elementary Classes at Sainte-Agathe's School.\n",
      "Reference: Nous habitions les bâtiments du Cours Supérieur de Sainte-Agathe.\n",
      "Predicted: Nous vivions dans l'édifice des classes élémentaires supérieures de l'école Sainte-Agathe's.\n",
      "\n",
      "English: My father, whom I used to call M. Seurel as did other pupils, was head of the Middle School and also of the Higher Elementary classes where pupils worked for the preliminary teacher's examination.\n",
      "Reference: Mon père, que j’appelais M. Seurel, comme les autres élèves, y dirigeait à la fois le Cours Supérieur, où l’on préparait le brevet d’instituteur, et le Cours Moyen.\n",
      "Predicted: Mon père, que j'appelais M. Seurel comme d'autres élèves, était chef de l'école moyenne et des classes élémentaires supérieures où les élèves travaillaient pour l'examen préliminaire de l'enseignant.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(6, 10):\n",
    "    print(f\"English: {text_en[i]}\")\n",
    "    print(f\"Reference: {ref_fr[i]}\")\n",
    "    print(f\"Predicted: {predict_fr[i]['translation_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8eF2w1edusF"
   },
   "source": [
    "## 5.5 Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VGoX9vleCtK"
   },
   "source": [
    "### 5.5.1 SacreBLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "2cd029428f5c4542b4f589dc88b9d792",
      "4a33b3a511d34c7bbee2b62e37664f6e",
      "ad7628c049e1481ea0cb5f1ffa3ecf87",
      "d913cb95edb74b2c933dfde4e7864652",
      "d6c47c6fe37741c7a5a0a7f8d52a3f73",
      "dcd3bb45f4ad45be934d2e4e8bf4df50",
      "425b4bff20fe4eec85cca26daffa6b33",
      "4d0bbf83f8474470902b24ac20932eab",
      "9296ec533e21459abab5114d7522cda1",
      "9625d095a76c42e58483230290ef9474",
      "0998440d106540b7849dcca9c2c87908"
     ]
    },
    "id": "GuZNY3zpdt_u",
    "outputId": "9762a397-7b97-47e3-cd03-e37c8abe64b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -q sacrebleu\n",
    "\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "Yg2q4LKTeLtd"
   },
   "outputs": [],
   "source": [
    "def postprocess_text(preds, refs):\n",
    "    # Sometimes we need a postprocess\n",
    "    preds = [pred['translation_text'].strip() for pred in preds]\n",
    "    refs = [ref.strip() for ref in refs]\n",
    "\n",
    "    return preds, refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "dZxW8xICeesa"
   },
   "outputs": [],
   "source": [
    "def compute_bleu_metrics(predict_fr, ref_fr):\n",
    "    predict_fr, ref_fr = postprocess_text(predict_fr, ref_fr)\n",
    "\n",
    "    print(\"Predicted: \", predict_fr[:5])\n",
    "    print(\"Reference: \", ref_fr[:5])\n",
    "\n",
    "    result = metric.compute(predictions=predict_fr, references=ref_fr)\n",
    "    result = {\"sacrebleu\": result[\"score\"]}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GLSchdXnfRZY",
    "outputId": "d66f4478-5687-4f41-d20a-ee5facc0d4d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  ['Le Wanderer', 'Alain-Fournier', 'Première partie', 'I', 'LE CONSEIL']\n",
      "Reference:  ['Le grand Meaulnes', 'Alain-Fournier', 'PREMIÈRE PARTIE', 'CHAPITRE PREMIER', 'LE PENSIONNAIRE']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sacrebleu': 15.840510492761013}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_bleu_metrics(predict_fr, ref_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85JPPgFxqH4h"
   },
   "source": [
    "### 5.5.2 METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "98L9uvS1fgy0"
   },
   "outputs": [],
   "source": [
    "def compute_meteor_metrics(predict_fr, ref_fr):\n",
    "    predict_fr, ref_fr = postprocess_text(predict_fr, ref_fr)\n",
    "\n",
    "    metric = evaluate.load(\"meteor\")\n",
    "    result = metric.compute(predictions=predict_fr, references=ref_fr)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "75b80550d73e4371a55ef634242ba17e",
      "2eeaf546b3af4809a56ddcc1aba3950a",
      "9eecb906c53947a5ab2653d9245cb31b",
      "f2936df97507488da9bec50f2a82683f",
      "9c5432d466f24d2391e08d0ae4b6efbd",
      "a72a643250fa4156a46234168950ea99",
      "f6ef82e6be8549ea9389a42fa9ca3db7",
      "be5b1c9906ed49afab02f3179062b6cd",
      "8e67cb8741bb4b2d991e5a1f9bba26e9",
      "ff6a8c0bb5bc4026a23e3de8b8ec2538",
      "f083c1c827aa4103b2a53f9fa3a1b5e2"
     ]
    },
    "id": "xExpT8Sgp6Hm",
    "outputId": "afe91217-9608-4df1-9274-fae384378fda"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/tunji/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/tunji/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/tunji/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'meteor': 0.3671263141061779}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_meteor_metrics(predict_fr, ref_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjIbNkSMqKY1"
   },
   "source": [
    "### 5.5.3 Bertscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "_w7vLdJXp8ye"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -q bert_score\n",
    "def compute_bertscore_metrics(predict_fr, ref_fr):\n",
    "    predict_fr, ref_fr = postprocess_text(predict_fr, ref_fr)\n",
    "    metric = evaluate.load(\"bertscore\")\n",
    "    result = metric.compute(predictions=predict_fr, references=ref_fr, model_type=\"distilbert-base-uncased\")\n",
    "\n",
    "    return sum(result['precision'])/len(result['precision']), sum(result['recall'])/len(result['recall']), sum(result['f1'])/len(result['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iRWhlVKnqPWd",
    "outputId": "ffe39bdc-7b93-471c-b701-7d615410cf0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8877962577342987, Recall: 0.8896603620052338, F1: 0.8883174216747284\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1 = compute_bertscore_metrics(predict_fr, ref_fr)\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRGxVckAsLB9"
   },
   "source": [
    "## 5.6 Exercise\n",
    "\n",
    "In the previous sections, we demonstrated how to evaluate translation models using the Evaluate library. However, for real-world projects, **I strongly recommend consulting the official documentation or GitHub repositories of the metrics you intend to use.** The metrics integrated into the Evaluate library often face update lags—for instance, a metric might already be at version 1.5, while Evaluate still deploys version 1.1. Additionally, the Evaluate library supports only a limited selection of commonly used metrics.\n",
    "\n",
    "In the next exercise, we encourage you to explore **reference-less** metrics to evaluate the performance of a translation model on the same En-Fr dataset. This means assessing the model's translation quality without relying on French reference translations. Instead, you will compare the model's French outputs directly with the original English inputs. You may need to explore libraries and resources beyond the Evaluate library to achieve this.\n",
    "\n",
    "Below are some suggested reference-less metrics you can explore (you are also welcome to choose others):\n",
    "\n",
    "- Prism: https://github.com/thompsonb/prism\n",
    "- NMTScore: https://github.com/ZurichNLP/nmtscore/tree/master\n",
    "- Cometkiwi: https://github.com/Unbabel/COMET\n",
    "- SBERT (Multilingual embedding model + cosine similarity): https://www.sbert.net/docs/sentence_transformer/pretrained_models.html#multilingual-models\n",
    "\n",
    "Feel free to explore, experiment, and apply these or other suitable reference-less metrics to evaluate your translation models!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group A\n",
    "\n",
    "- Oyetunji ABIOYE\n",
    "- Mehsen AZIZI\n",
    "- Mohammad AL TAKACH\n",
    "- Hawawou  Oumarou Tchapchet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "4ITr1rBwy4vI"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d07fd24913f4e45af96a71cfdd5eb2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cfa43546ca94775872e9026fcad9d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a75be2689a47febcdef90a02c02bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94605d4fd644bd0b6180510a13b67bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e1713b6070413581893dcb06150d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bdbbb42f42343f488e8d5c68343d75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2add8db3054283997a3fbc7b1a8659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca82b0c6c99451e981ea896088e88ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2a3a10e2814edb935fdb192853c1ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997ac29832a74f3493c9f377aa7b93eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0841ee4eb4ea48c8a00783bc992dce8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# en_embedding_instruction =\n",
    "en_embedding = model.encode(text_en)\n",
    "fr_embedding = model.encode(predict_fr)\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_similarity = cos_sim(en_embedding, fr_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 100])\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Similarity: 0.2794296443462372\n"
     ]
    }
   ],
   "source": [
    "# Compute average cosine similarity\n",
    "avg_cosine_similarity = cosine_similarity.mean()\n",
    "print(f\"Average Cosine Similarity: {avg_cosine_similarity}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nn_speech_recognition-qgr9tgLb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0998440d106540b7849dcca9c2c87908": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2cd029428f5c4542b4f589dc88b9d792": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4a33b3a511d34c7bbee2b62e37664f6e",
       "IPY_MODEL_ad7628c049e1481ea0cb5f1ffa3ecf87",
       "IPY_MODEL_d913cb95edb74b2c933dfde4e7864652"
      ],
      "layout": "IPY_MODEL_d6c47c6fe37741c7a5a0a7f8d52a3f73"
     }
    },
    "2eeaf546b3af4809a56ddcc1aba3950a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a72a643250fa4156a46234168950ea99",
      "placeholder": "​",
      "style": "IPY_MODEL_f6ef82e6be8549ea9389a42fa9ca3db7",
      "value": "Downloading builder script: 100%"
     }
    },
    "425b4bff20fe4eec85cca26daffa6b33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a33b3a511d34c7bbee2b62e37664f6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcd3bb45f4ad45be934d2e4e8bf4df50",
      "placeholder": "​",
      "style": "IPY_MODEL_425b4bff20fe4eec85cca26daffa6b33",
      "value": "Downloading builder script: 100%"
     }
    },
    "4d0bbf83f8474470902b24ac20932eab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75b80550d73e4371a55ef634242ba17e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2eeaf546b3af4809a56ddcc1aba3950a",
       "IPY_MODEL_9eecb906c53947a5ab2653d9245cb31b",
       "IPY_MODEL_f2936df97507488da9bec50f2a82683f"
      ],
      "layout": "IPY_MODEL_9c5432d466f24d2391e08d0ae4b6efbd"
     }
    },
    "8e67cb8741bb4b2d991e5a1f9bba26e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9296ec533e21459abab5114d7522cda1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9625d095a76c42e58483230290ef9474": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c5432d466f24d2391e08d0ae4b6efbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9eecb906c53947a5ab2653d9245cb31b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be5b1c9906ed49afab02f3179062b6cd",
      "max": 7021,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e67cb8741bb4b2d991e5a1f9bba26e9",
      "value": 7021
     }
    },
    "a72a643250fa4156a46234168950ea99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad7628c049e1481ea0cb5f1ffa3ecf87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d0bbf83f8474470902b24ac20932eab",
      "max": 8146,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9296ec533e21459abab5114d7522cda1",
      "value": 8146
     }
    },
    "be5b1c9906ed49afab02f3179062b6cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6c47c6fe37741c7a5a0a7f8d52a3f73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d913cb95edb74b2c933dfde4e7864652": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9625d095a76c42e58483230290ef9474",
      "placeholder": "​",
      "style": "IPY_MODEL_0998440d106540b7849dcca9c2c87908",
      "value": " 8.15k/8.15k [00:00&lt;00:00, 556kB/s]"
     }
    },
    "dcd3bb45f4ad45be934d2e4e8bf4df50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f083c1c827aa4103b2a53f9fa3a1b5e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2936df97507488da9bec50f2a82683f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff6a8c0bb5bc4026a23e3de8b8ec2538",
      "placeholder": "​",
      "style": "IPY_MODEL_f083c1c827aa4103b2a53f9fa3a1b5e2",
      "value": " 7.02k/7.02k [00:00&lt;00:00, 246kB/s]"
     }
    },
    "f6ef82e6be8549ea9389a42fa9ca3db7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff6a8c0bb5bc4026a23e3de8b8ec2538": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
